{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cc2619f-dbfc-43e8-80ae-ba8c6b8b3075",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 1: Imports & Config\n",
    "import json, random, uuid, time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import pyarrow\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "cfg = json.loads(Path(\"/Workspace/Users/santiagobustosp@gmail.com/medellin-bigdata-poc/notebooks/1_simulation/sim_config.json\").read_text()) # Cambiar el nombre de ususario antes de ejecutar\n",
    "base     = Path(cfg[\"base_path\"])\n",
    "paths    = cfg[\"paths\"]\n",
    "interval = cfg[\"interval_seconds\"]\n",
    "qty_min, qty_max = cfg[\"quantity_range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb31f502-a5ad-4ab9-a80b-0bf60f43d982",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 2: Carga de insumos\n",
    "gdf_neigh = gpd.read_parquet(base/paths[\"neighborhoods\"])       # barrios\n",
    "mask_geom = gpd.read_parquet(base/paths[\"city_mask\"]).geometry.iloc[0]  # contorno Medellín\n",
    "df_cust   = pd.read_parquet(base/paths[\"customers\"])            # clientes\n",
    "df_emp    = pd.read_parquet(base/paths[\"employees\"])            # empleados\n",
    "# print(f\"✅ Barrios: {len(gdf_neigh)} | Clientes: {len(df_cust)} | Empleados: {len(df_emp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ac75e42-b38b-4488-bfc6-9d9a38f17e45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 3: Funciones de muestreo y generación de evento\n",
    "def sample_point(poly):\n",
    "    minx,miny,maxx,maxy = poly.bounds\n",
    "    while True:\n",
    "        p = Point(random.uniform(minx, maxx), random.uniform(miny, maxy))\n",
    "        if poly.contains(p) and mask_geom.contains(p):\n",
    "            return p\n",
    "\n",
    "# Como usamos una distribución gausiana truncada, debemos definir los parametros \n",
    "# Parámetros de la distribución truncada\n",
    "mu = 25      # número promedio de compras por simulación\n",
    "sigma = 10   # dispersión\n",
    "min_val = qty_min  # mínimo número de compras por intervalo\n",
    "max_val = qty_max # máximo aceptado\n",
    "\n",
    "# Convertir a valores estandarizados\n",
    "min_val = (min_val - mu) / sigma\n",
    "max_val = (max_val - mu) / sigma\n",
    "\n",
    "def gen_event():\n",
    "    b  = gdf_neigh.sample(1).iloc[0]\n",
    "    pt = sample_point(b.geometry)\n",
    "    return {\n",
    "      \"order_id\":          str(uuid.uuid4()),\n",
    "      \"date\":              datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"),\n",
    "      \"customer_id\":       int(df_cust.customer_id.sample(1).iloc[0]),\n",
    "      \"employee_id\":       int(df_emp.employee_id.sample(1).iloc[0]),\n",
    "      \"quantity_products\": int(truncnorm(min_val, max_val, loc=mu, scale=sigma).rvs()),\n",
    "      \"latitude\":          pt.y,\n",
    "      \"longitude\":         pt.x,\n",
    "      \"neighborhood\":      b[\"IDENTIFICACION\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6ac7602-6eb5-411a-92b9-5e91fd63ed5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 4: Preparar carpeta timestamp\n",
    "ts      = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_dir = base/paths[\"output_dir\"]/ts\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(\"▶️ Carpeta de simulación:\", out_dir.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "176db9e7-edb8-42d3-aee0-3973a2968a5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 5 optimizada para prueba rápida:\n",
    "# Defninimos el número de eventos a generar como una variable aleatoria con distribución normal truncada\n",
    "\n",
    "# Parámetros de la distribución truncada\n",
    "mu = 8      # número promedio de compras por simulación\n",
    "sigma = 5   # dispersión\n",
    "min_val = 0  # mínimo número de compras por intervalo\n",
    "max_val = 30 # máximo aceptado\n",
    "\n",
    "# Convertir a valores estandarizados\n",
    "a = (min_val - mu) / sigma\n",
    "b = (max_val - mu) / sigma\n",
    "N = int(truncnorm(a, b, loc=mu, scale=sigma).rvs())\n",
    "\n",
    "# Corremos el bucle para generar los eventos \n",
    "for _ in range(N):\n",
    "    e = gen_event()\n",
    "    (out_dir/f\"{e['order_id']}.json\").write_text(json.dumps(e))\n",
    "print(f\"✅ Generados {N} eventos en {out_dir.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90c73242-907f-462c-b435-a435b021601b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 6: Leer los JSONs y crear DataFrame Spark\n",
    "files   = list(out_dir.glob(\"*.json\"))\n",
    "events  = [json.loads(p.read_text()) for p in files]\n",
    "df_raw  = spark.createDataFrame(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e90766f-79a0-418d-bbee-ae035c91457f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 7: Geo‑join para calcular 'district'  \n",
    "from shapely.geometry import Point\n",
    "\n",
    "# 1) Convertir df_raw a pandas para hacer spatial join\n",
    "pdf = df_raw.toPandas()\n",
    "pdf = df_raw.toPandas().drop(columns=[\"neighborhood\"])\n",
    "\n",
    "# 2) Crear GeoDataFrame puntual con lat/lon\n",
    "pdf[\"geometry\"] = pdf.apply(lambda r: Point(r.longitude, r.latitude), axis=1)\n",
    "gpdf = gpd.GeoDataFrame(pdf, geometry=\"geometry\", crs=gdf_neigh.crs)\n",
    "\n",
    "# 3) Spatial join: cada punto recibe el polígono que lo contiene\n",
    "#    Suponemos gdf_neigh tiene columna 'NOMBRE' con el barrio\n",
    "gpdf = gpd.sjoin(gpdf, gdf_neigh[[\"IDENTIFICACION\",\"NOMBRE\", \"geometry\"]], how=\"left\", predicate=\"within\")\n",
    "\n",
    "# 4) Renombrar la columna resultante y limpiar índices\n",
    "# gpdf = gpdf.rename(columns={\"IDENTIFICACION\": \"district\", \"NOMBRE\": \"neighborhood\"}).drop(columns=[\"index_right\"])\n",
    "gpdf = gpdf.rename(columns={\"IDENTIFICACION\": \"neighborhood\", \"NOMBRE\": \"district\"}).drop(columns=[\"index_right\"])\n",
    "\n",
    "\n",
    "# 5) Volver a Spark\n",
    "df_raw = spark.createDataFrame(gpdf.drop(columns=\"geometry\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48148cf7-e6e8-4ca7-819b-d853bcb22c8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 8: Transformar df_raw al esquema Bronze\n",
    "from pyspark.sql.functions import (\n",
    "    to_timestamp, date_format,\n",
    "    year, month, dayofmonth,\n",
    "    hour, minute, second\n",
    ")\n",
    "\n",
    "df_bronze = (\n",
    "    df_raw\n",
    "      # 1) Parsear timestamp\n",
    "      .withColumn(\"event_ts\", to_timestamp(\"date\", \"dd/MM/yyyy HH:mm:ss\"))\n",
    "      # 2) Partición diaria en formato ddMMyyyy\n",
    "      .withColumn(\"partition_date\", date_format(\"event_ts\", \"ddMMyyyy\"))\n",
    "      # 3) Desglosar fecha/hora\n",
    "      .withColumn(\"event_year\",   year(\"event_ts\"))\n",
    "      .withColumn(\"event_month\",  month(\"event_ts\"))\n",
    "      .withColumn(\"event_day\",    dayofmonth(\"event_ts\"))\n",
    "      .withColumn(\"event_hour\",   hour(\"event_ts\"))\n",
    "      .withColumn(\"event_minute\", minute(\"event_ts\"))\n",
    "      .withColumn(\"event_second\", second(\"event_ts\"))\n",
    "      # 4) Renombrar/seleccionar columnas según spec\n",
    "      .select(\n",
    "         \"partition_date\",\n",
    "         \"order_id\",\n",
    "         \"neighborhood\",\n",
    "         \"customer_id\",\n",
    "         \"employee_id\",\n",
    "         \"event_ts\",\n",
    "         \"event_year\",\"event_month\",\"event_day\",\n",
    "         \"event_hour\",\"event_minute\",\"event_second\",\n",
    "         \"latitude\",\"longitude\",\n",
    "         \"district\",\n",
    "         \"quantity_products\"\n",
    "      )\n",
    ")\n",
    "\n",
    "# Inspección rápida del resultado\n",
    "# display(df_bronze.limit(5))\n",
    "# df_bronze.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "287a15db-a5ba-4420-afea-eed166fb97ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Celda X: Crear el schema de prueba\n",
    "CREATE DATABASE IF NOT EXISTS poctesting;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bafe8abb-a7a6-40c6-b02e-421077a42d8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PASO 9: Persistir en Delta como managed table\n",
    "# Si la tabla no existe, la crea; si existe, hace append.\n",
    "\n",
    "# 1) Guardar como tabla delta en el metastore\n",
    "(\n",
    "  df_bronze\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"append\")\n",
    "    .saveAsTable(\"poctesting.bronze_events\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dbccbbf-8f92-4e50-bc64-65598901d5da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE DATABASE EXTENDED poctesting;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "geopandas",
     "pyarrow",
     "numpy==1.24.4",
     "pandas==2.0.3",
     "scipy==1.11.1"
    ],
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7389033671933357,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "setup_optimize",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
