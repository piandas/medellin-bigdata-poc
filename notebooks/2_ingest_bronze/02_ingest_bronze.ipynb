{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a43319ef-6685-48e1-ba85-70a9f66457e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Imports y SparkSession\n",
    "# ==============================\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    to_timestamp, date_format,\n",
    "    year, month, dayofmonth,\n",
    "    hour, minute, second, col\n",
    ")\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "from shapely.geometry import Point, shape\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"02_ingest_bronze\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3314a0d-1f97-4059-8728-b86bc0c27757",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Recarga de config y geometrías\n",
    "# ==============================\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "# 1) Parámetros de simulación\n",
    "cfg       = json.loads(\n",
    "    Path(\"/Workspace/Users/santiagobustosp@gmail.com/medellin-bigdata-poc/notebooks/1_simulation/sim_config.json\")\n",
    "    .read_text()\n",
    ")\n",
    "base      = Path(cfg[\"base_path\"])\n",
    "run_ts    = \"<el mismo timestamp generado en NB1>\"\n",
    "input_dir = base / \"data\" / \"sim-events\" / run_ts\n",
    "\n",
    "# 2) Carga de geometrías con GeoPandas para evitar el error de 'bytes'\n",
    "raw_dir   = base / \"data\" / \"raw\"\n",
    "gdf_neigh = gpd.read_parquet(f\"{raw_dir}/medellin_neighborhoods.parquet\")\n",
    "gdf_mask  = gpd.read_parquet(f\"{raw_dir}/50001.parquet\")\n",
    "\n",
    "# 3) Preparar estructuras para los UDFs\n",
    "neigh_list = gdf_neigh.to_dict(\"records\")\n",
    "mask_geom  = shape(gdf_mask.loc[0, \"geometry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2002ee18-2ccf-45d4-9411-81837e6e074e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# UDFs para district y neighborhood\n",
    "# ==============================\n",
    "def find_district(lat, lon):\n",
    "    pt = Point(lon, lat)\n",
    "    for b in neigh_list:\n",
    "        if shape(b[\"geometry\"]).contains(pt):\n",
    "            return b[\"IDENTIFICACION\"]\n",
    "    return None\n",
    "\n",
    "def find_neighborhood(lat, lon):\n",
    "    pt = Point(lon, lat)\n",
    "    for b in neigh_list:\n",
    "        if shape(b[\"geometry\"]).contains(pt):\n",
    "            return b[\"NOMBRE\"]\n",
    "    return None\n",
    "\n",
    "find_district_udf     = udf(find_district, StringType())\n",
    "find_neighborhood_udf = udf(find_neighborhood, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f76eac53-c3dd-4c0d-8cc8-068762b83f18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Celda 4 – Leer tabla raw_events_temp y enriquecer\n",
    "# ==============================\n",
    "# (1) Cargamos directamente la tabla Delta con los eventos simulados\n",
    "df_raw = spark.table(\"unalwater.raw_events_temp\")\n",
    "\n",
    "# (2) Aplicamos los UDFs espaciales\n",
    "df_events = (\n",
    "  df_raw\n",
    "    .withColumn(\"district\",     find_district_udf(\"latitude\", \"longitude\"))\n",
    "    .withColumn(\"neighborhood\", find_neighborhood_udf(\"latitude\", \"longitude\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c5a200e-2d4a-4c9e-b5ba-935d6b7871c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Transformar al esquema Bronze\n",
    "# ==============================\n",
    "df_bronze = (\n",
    "  df_events\n",
    "    .withColumn(\"event_ts\",      to_timestamp(\"date\", \"dd/MM/yyyy HH:mm:ss\"))\n",
    "    .withColumn(\"partition_date\", date_format(\"event_ts\", \"ddMMyyyy\"))\n",
    "    .withColumn(\"event_year\",     year(\"event_ts\"))\n",
    "    .withColumn(\"event_month\",    month(\"event_ts\"))\n",
    "    .withColumn(\"event_day\",      dayofmonth(\"event_ts\"))\n",
    "    .withColumn(\"event_hour\",     hour(\"event_ts\"))\n",
    "    .withColumn(\"event_minute\",   minute(\"event_ts\"))\n",
    "    .withColumn(\"event_second\",   second(\"event_ts\"))\n",
    "    .select(\n",
    "      \"partition_date\", \"order_id\", \"neighborhood\", \"customer_id\",\n",
    "      \"employee_id\", col(\"date\").alias(\"event_date\"),\n",
    "      \"event_day\", \"event_hour\", \"event_minute\", \"event_month\",\n",
    "      \"event_second\", \"event_year\", \"latitude\", \"longitude\",\n",
    "      \"district\", \"quantity_products\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4b6d975-ed97-4783-b588-a130fd31d2c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Guardar en Delta Lake\n",
    "# ==============================\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS unalwater\")\n",
    "\n",
    "(\n",
    "  df_bronze\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"append\")\n",
    "    .partitionBy(\"partition_date\")\n",
    "    .saveAsTable(\"unalwater.bronze_events\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "geopandas",
     "pyarrow",
     "numpy==1.24.4",
     "pandas==2.0.3"
    ],
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7389033671933834,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02_ingest_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
