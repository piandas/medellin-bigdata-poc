{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cddcedf-0e32-4eb6-8040-3c352a1abd30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beaeac23-a3c0-4fdb-a6c8-f979fbe4834c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- DROP TABLE poctesting.silver_events;\n",
    "-- DROP TABLE poctesting.bronze_events;\n",
    "-- DROP TABLE poctesting.gold_events;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d6c0b07-62e3-43c4-9649-cc16cfd88b18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for i in range(150):\n",
    "    print(f\"▶️ Ejecutando iteración {i+1}\")\n",
    "    dbutils.notebook.run(\"./setup_optimize\", timeout_seconds=200)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2355ee6a-08ce-430a-aa48-7a15e1d58973",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %run ./setup_optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09016fed-ec3a-47a1-b9f4-5704c6a8f693",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Traemos los datos de prueba bronces\n",
    "data = spark.table(\"poctesting.bronze_events\")\n",
    "display(data.limit(5))\n",
    "print(f\"El archivo tiene {data.count()} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "206d945b-a866-4105-8279-c412e933cadd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Importar bronze\n",
    "df_bronze = spark.table(\"poctesting.bronze_events\")\n",
    "\n",
    "# Registros completos\n",
    "df_completos = df_bronze.filter(\n",
    "    col(\"neighborhood\").isNotNull() & col(\"district\").isNotNull()\n",
    ")\n",
    "\n",
    "# Registros incompletos\n",
    "df_incompletos = df_bronze.filter(\n",
    "    col(\"neighborhood\").isNull() | col(\"district\").isNull()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4298d0dc-7874-40f7-a767-75a634d58dc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, row_number, count\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.neighbors import BallTree\n",
    "import numpy as np\n",
    "\n",
    "def corregir_con_sjoin_y_balltree(df_spark, path_parquet_neigh, schema):\n",
    "    df = df_spark.toPandas()\n",
    "    if df.empty:\n",
    "        return spark.createDataFrame([], schema)\n",
    "\n",
    "    df[\"geometry\"] = df.apply(lambda row: Point(row[\"longitude\"], row[\"latitude\"]), axis=1)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "    gdf_neigh = gpd.read_parquet(path_parquet_neigh)[[\"NOMBRE\", \"IDENTIFICACION\", \"geometry\"]]\n",
    "    gdf_neigh = gdf_neigh.dropna(subset=[\"geometry\"]).set_crs(\"EPSG:4326\")\n",
    "\n",
    "    gdf = gdf.to_crs(\"EPSG:3857\")\n",
    "    gdf_neigh = gdf_neigh.to_crs(\"EPSG:3857\")\n",
    "\n",
    "    gdf_joined = gpd.sjoin(gdf, gdf_neigh, how=\"left\", predicate=\"within\")\n",
    "    gdf[\"neighborhood\"] = gdf_joined[\"NOMBRE\"]\n",
    "    gdf[\"district\"] = gdf_joined[\"IDENTIFICACION\"]\n",
    "\n",
    "    gdf_nulos = gdf[gdf[\"neighborhood\"].isna()].copy()\n",
    "    if not gdf_nulos.empty:\n",
    "        centroids = gdf_neigh.geometry.centroid\n",
    "        neigh_coords = np.array([[pt.y, pt.x] for pt in centroids])\n",
    "        point_coords = np.array([[pt.y, pt.x] for pt in gdf_nulos.geometry])\n",
    "        tree = BallTree(np.deg2rad(neigh_coords), metric=\"haversine\")\n",
    "        dist, idx = tree.query(np.deg2rad(point_coords), k=1)\n",
    "        gdf.loc[gdf[\"neighborhood\"].isna(), \"neighborhood\"] = gdf_neigh.iloc[idx.flatten()][\"NOMBRE\"].values\n",
    "        gdf.loc[gdf[\"district\"].isna(), \"district\"] = gdf_neigh.iloc[idx.flatten()][\"IDENTIFICACION\"].values\n",
    "\n",
    "    gdf = gdf.dropna(subset=[\"neighborhood\", \"district\"])\n",
    "\n",
    "    if gdf.empty:\n",
    "        return spark.createDataFrame([], schema)\n",
    "    else:\n",
    "        return spark.createDataFrame(gdf.drop(columns=[\"geometry\"]))\n",
    "\n",
    "def actualizar_silver_eventos(df_completos, df_incompletos, path_parquet_neigh):\n",
    "    nombre_tabla_silver = \"poctesting.silver_events\"\n",
    "    schema = df_incompletos.schema\n",
    "\n",
    "    # Corregir los incompletos\n",
    "    df_corregido = corregir_con_sjoin_y_balltree(df_incompletos, path_parquet_neigh, schema)\n",
    "    cantidad_corregidos = df_corregido.count()\n",
    "    cantidad_completos = df_completos.count()\n",
    "\n",
    "    # Unir completados\n",
    "    if df_corregido.limit(1).count() == 0:\n",
    "        print(f\"⚠️ No se corrigieron registros incompletos. Se usará solo df_completos ({cantidad_completos}).\")\n",
    "        df_union = df_completos\n",
    "    else:\n",
    "        print(f\"✅ Se corrigieron {cantidad_corregidos} registros. Total con completos: {cantidad_completos + cantidad_corregidos}\")\n",
    "        df_union = df_completos.unionByName(df_corregido)\n",
    "\n",
    "    # Eliminar duplicados por order_id conservando el de mayor quantity_products\n",
    "    window_spec = Window.partitionBy(\"order_id\").orderBy(col(\"quantity_products\").desc())\n",
    "    df_union_dedup = df_union.withColumn(\"rn\", row_number().over(window_spec)).filter(\"rn = 1\").drop(\"rn\")\n",
    "\n",
    "    # Cargar datos existentes (si los hay)\n",
    "    tabla_existe = spark.catalog.tableExists(nombre_tabla_silver)\n",
    "    if tabla_existe:\n",
    "        df_existente = spark.table(nombre_tabla_silver)\n",
    "        df_todo = df_existente.unionByName(df_union_dedup)\n",
    "\n",
    "        # Deduplicar final por order_id (mantener mayor quantity_products)\n",
    "        window_final = Window.partitionBy(\"order_id\").orderBy(col(\"quantity_products\").desc())\n",
    "        df_final = df_todo.withColumn(\"rn\", row_number().over(window_final)).filter(\"rn = 1\").drop(\"rn\")\n",
    "    else:\n",
    "        df_final = df_union_dedup\n",
    "\n",
    "    # Guardar en tabla silver\n",
    "    modo = \"overwrite\" if not tabla_existe else \"overwrite\"\n",
    "    df_final.write.mode(modo).saveAsTable(nombre_tabla_silver)\n",
    "\n",
    "    # Verificación final de duplicados\n",
    "    df_verif = spark.table(nombre_tabla_silver)\n",
    "    df_check = df_verif.groupBy(\"order_id\").agg(count(\"*\").alias(\"cantidad\")).filter(\"cantidad > 1\")\n",
    "\n",
    "    if df_check.count() > 0:\n",
    "        print(f\"❌ Duplicados encontrados en 'order_id': {df_check.count()}\")\n",
    "        display(df_check)\n",
    "    else:\n",
    "        print(f\"✅ Tabla 'silver_eventos' actualizada correctamente con {df_final.count()} registros únicos por orden.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ba35b07-63c0-43a8-8596-fd4259a8d19e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path_parquet_neigh = \"/Workspace/Users/danielale22rojas@gmail.com//medellin-bigdata-poc/data/raw/medellin_neighborhoods.parquet\"\n",
    "actualizar_silver_eventos(df_completos, df_incompletos, path_parquet_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "309b819f-9d69-4b92-911a-dff07f1d4ac3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_silver = spark.table(\"poctesting.silver_events\")\n",
    "# df_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"poctesting.silver_events\")\n",
    "print(f\"Descartamos {df_bronze.count() - df_silver.count()} registros con información faltante\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df263bcd-38b8-45b6-b2c8-9421094ea9b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- cual es el numero promedio de produtos vendidos\n",
    "-- SELECT avg(quantity_products) FROM poctesting.silver_events;\n",
    "-- SELECT avg(quantity_products) FROM poctesting.bronze_events;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "161f1303-c988-4ad2-b507-d6069dd7a9d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Contrucción de ventanas para gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba944bfb-5d5e-4a81-a8c3-9b8deccf1a91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Ventanas por barrio y empleado\n",
    "window_neigh = Window.partitionBy(\"neighborhood\")\n",
    "window_emp_total = Window.partitionBy(\"employee_id\")\n",
    "window_rank_global = Window.orderBy(F.sum(\"quantity_products\").over(window_emp_total).desc())\n",
    "\n",
    "# Aplicar funciones de ventana\n",
    "df_gold = df_silver \\\n",
    "    .withColumn(\"total_by_neighborhood\", F.sum(\"quantity_products\").over(window_neigh)) \\\n",
    "    .withColumn(\"total_by_employee\", F.sum(\"quantity_products\").over(window_emp_total)) \\\n",
    "    .withColumn(\"rank_employee_quantity\", F.dense_rank().over(window_rank_global)) #\\\n",
    "    #.withColumn(\"cume_dist_employee\", F.cume_dist().over(window_rank_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29429ca2-889a-484d-b45d-81bd473c65e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Ventanas para gold\n",
    "# Partimos de Silver\n",
    "df_silver = spark.table(\"poctesting.silver_events\")\n",
    "\n",
    "# Ventanas\n",
    "window_neigh = Window.partitionBy(\"neighborhood\")\n",
    "window_neigh_month = Window.partitionBy(\"neighborhood\", \"event_year\", \"event_month\")\n",
    "window_rank = Window.partitionBy(\"event_month\").orderBy(F.sum(\"quantity_products\").over(window_neigh_month).desc())\n",
    "window_day = Window.partitionBy(\"neighborhood\", \"event_year\", \"event_month\", \"event_day\")\n",
    "\n",
    "# Construcción de métricas\n",
    "df_gold = df_silver \\\n",
    "    .withColumn(\"total_by_neighborhood\", F.sum(\"quantity_products\").over(window_neigh)) \\\n",
    "    .withColumn(\"avg_by_neighborhood\", F.avg(\"quantity_products\").over(window_neigh)) \\\n",
    "    .withColumn(\"count_orders_by_neigh\", F.count(\"order_id\").over(window_neigh)) \\\n",
    "    .withColumn(\"unique_customers_by_neigh\", F.approx_count_distinct(\"customer_id\").over(window_neigh)) \\\n",
    "    .withColumn(\"monthly_total\", F.sum(\"quantity_products\").over(window_neigh_month)) \\\n",
    "    .withColumn(\"monthly_avg\", F.avg(\"quantity_products\").over(window_neigh_month)) \\\n",
    "    .withColumn(\"rank_in_month\", F.dense_rank().over(window_rank)) \\\n",
    "    .withColumn(\"orders_per_day\", F.count(\"order_id\").over(window_day))\n",
    "\n",
    "# Persistir en tabla Gold\n",
    "df_gold.write.mode(\"overwrite\").saveAsTable(\"poctesting.gold_events\")\n",
    "\n",
    "print(f\"✅ Tabla 'poctesting.gold_events' creada con {df_gold.count()} registros enriquecidos.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49c62002-5ab4-4181-9d50-dfe26d48678e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1753719688440}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_gold.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2970e519-cdf5-4bac-9981-e6ecda861f2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Graficos\n",
    "Realizamos los siguientes graficos como aporte a la solución planteada en la POC de UnalWater\n",
    "1. Grafico de dispersión de los puntos\n",
    "2. Mapa de cloropletas por barrio\n",
    "3. Mapa de densidad de Kernel\n",
    "4. Histograma de cantidad de productos vendidos\n",
    "5. Histograma de productos vendidos por horas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6658cf2a-340a-45fd-93ea-8fcdebe872f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Primero debemos leer el dataframe desde silver y recuperar la geometría de los puntos y también corregir la geometría de los barrios, que tiene huecos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9a45c6d-605d-4926-b6d2-02a0ed6b9c32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from shapely.validation import make_valid\n",
    "import geopandas as gpd\n",
    "\n",
    "path_parquet_neigh = \"/Workspace/Users/danielale22rojas@gmail.com//medellin-bigdata-poc/data/raw/medellin_neighborhoods.parquet\"\n",
    "gdf_barrios = gpd.read_parquet(path_parquet_neigh) \n",
    "\n",
    "gdf_barrios[\"geometry\"] = gdf_barrios[\"geometry\"].apply(make_valid)\n",
    "\n",
    "# Primero corregimos el nombre\n",
    "gdf_barrios.loc[gdf_barrios[\"NOMBRE\"].isna(), \"NOMBRE\"] = \"ARANJUEZ\"\n",
    "\n",
    "# Luego disolvemos por el nombre\n",
    "gdf_barrios = gdf_barrios.dissolve(by=\"NOMBRE\", as_index=False)\n",
    "\n",
    "gdf_barrios[\"NOMBRE\"] = gdf_barrios[\"NOMBRE\"].str.replace(\"CORREGIMIENTO DE \", \"\", regex=True)\n",
    "gdf_barrios[\"NOMBRE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bf23071-00f5-4846-9d77-fd23d4b55808",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def cargar_silver_como_gdf(nombre_tabla=\"poctesting.gold_events\", crs=\"EPSG:4326\"):\n",
    "    \"\"\"\n",
    "    Carga la tabla Silver desde Spark y la convierte en un GeoDataFrame.\n",
    "    \"\"\"\n",
    "    # Leer la tabla desde Spark\n",
    "    df_gold = spark.table(nombre_tabla)\n",
    "    \n",
    "    # Pasar a Pandas\n",
    "    pdf = df_gold.toPandas()\n",
    "\n",
    "    # Crear el \"geometry\" a partir de lon y lat\n",
    "    pdf[\"geometry\"] = pdf.apply(lambda row: Point(row[\"longitude\"], row[\"latitude\"]), axis=1)\n",
    "    \n",
    "    # Construir GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(pdf, geometry=\"geometry\", crs=crs)\n",
    "    \n",
    "    return gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b6154f9-4e54-4507-9b8a-dcb363a764fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# bd es la base de datos gold importada como un GeodataFrame de pandas\n",
    "bd = cargar_silver_como_gdf(\"poctesting.gold_events\", \"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1d8f689-1b5c-4a1e-ba1d-86b4de3d91e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Grafico de dispersión de los puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86c8a20e-c804-48cd-87ec-72e74cb9be73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "\n",
    "plot = sbn.jointplot(\n",
    "    x='longitude', \n",
    "    y='latitude', \n",
    "    data=bd, \n",
    "    s=5,  # Tamaño de los puntos\n",
    "    height=8\n",
    ")\n",
    "\n",
    "# Agregar título y etiquetas\n",
    "plot.fig.suptitle(\"Distribución de puntos de ventas\", y=1.02, fontsize=16)\n",
    "plot.set_axis_labels(\"Longitud\", \"Latitud\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84da9739-9d3b-4ea4-b33c-eaaa0a49355d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import geopandas as gpd\n",
    "\n",
    "# 2. Crear el jointplot\n",
    "plot = sbn.jointplot(\n",
    "    x='longitude', \n",
    "    y='latitude', \n",
    "    data=bd, \n",
    "    s=5, \n",
    "    height=8\n",
    ")\n",
    "\n",
    "# 3. Obtener el eje principal del jointplot\n",
    "ax = plot.ax_joint\n",
    "\n",
    "# 4. Dibujar los límites de barrios encima\n",
    "gdf_barrios.boundary.plot(ax=ax, color=\"black\", linewidth=0.5)\n",
    "\n",
    "# 5. Personalizar títulos y etiquetas\n",
    "plot.fig.suptitle(\"Distribución de puntos de venta con límites de barrios\", y=1.02, fontsize=16)\n",
    "plot.set_axis_labels(\"Longitud\", \"Latitud\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "668a8824-a07a-4ef0-b281-d0ddb36721b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Mapa de cloropletas por barrio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3909a0fa-a154-4360-b429-5c8b076b5723",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_gold = spark.table(\"poctesting.gold_events\")\n",
    "display(df_gold.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f096e05-74f0-434f-b282-906bc977c823",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Cargar los polígonos de los barrios\n",
    "gdf = gpd.read_parquet(path_parquet_neigh) \n",
    "gdf = gdf[[\"NOMBRE\", \"geometry\"]]\n",
    "\n",
    "# 2. Leer Gold y dejar un registro por barrio\n",
    "pdf_gold = df_gold.select(\"neighborhood\", \"avg_by_neighborhood\").distinct().toPandas()\n",
    "\n",
    "# 3. Unir con datos espaciales\n",
    "gdf_merged = gdf.merge(pdf_gold, left_on=\"NOMBRE\", right_on=\"neighborhood\", how=\"left\")\n",
    "gdf_merged[\"NOMBRE\"] = gdf_merged[\"NOMBRE\"].str.replace(\"CORREGIMIENTO DE \", \"\", regex=True)\n",
    "\n",
    "# 4. Crear gráfico\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "gdf_merged.plot(\n",
    "    column=\"avg_by_neighborhood\",\n",
    "    cmap=\"OrRd\",\n",
    "    edgecolor=\"black\",\n",
    "    legend=True,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# 5. Rotular barrios usando centroide\n",
    "for idx, row in gdf_merged.iterrows():\n",
    "    if row[\"geometry\"] is not None:\n",
    "        centroid = row[\"geometry\"].centroid\n",
    "        plt.text(\n",
    "            centroid.x,\n",
    "            centroid.y,\n",
    "            row[\"NOMBRE\"],\n",
    "            fontsize=6,\n",
    "            ha=\"center\",\n",
    "            va=\"center\"\n",
    "        )\n",
    "\n",
    "plt.title(\"Total de Productos por Barrio - Medellín\", fontsize=15)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Quitar la palabra corregimiento de los nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b4297be-5b58-4be5-ac9b-f141f95de0e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gdf_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89f04985-a16b-49b9-b326-a02db2869d02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Unir con los totales (eliminamos duplicados porque total_by_neighborhood se repite por punto)\n",
    "totales = bd[[\"neighborhood\", \"total_by_neighborhood\"]].drop_duplicates()\n",
    "gdf_clorop = gdf_barrios.merge(totales, left_on=\"NOMBRE\", right_on=\"neighborhood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b264184-5d65-46e6-948a-71002df29cc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 3. Graficar coroplético\n",
    "f, ax = plt.subplots(1, figsize=(12,7))\n",
    "gdf_clorop.plot(\n",
    "    ax=ax,\n",
    "    column=\"total_by_neighborhood\",  # usamos el total ya calculado\n",
    "    legend=True,\n",
    "    scheme=\"Quantiles\",\n",
    "    legend_kwds={\"fmt\": \"{:.0f}\"},\n",
    "    cmap=\"Blues\",\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.5\n",
    ")\n",
    "ax.set_axis_off()\n",
    "ax.set_title(\"Total de productos vendidos por barrio\", fontsize=14)\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5f85c14-13ff-4a32-868d-4cacf5cd18b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Mapa de densidad de Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7064b810-c49f-4105-a58c-d2832a1c94af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import geopandas as gpd\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "# 2. Crear figura\n",
    "f, ax = plt.subplots(figsize=(10, 12))\n",
    "\n",
    "# 3. KDE con seaborn\n",
    "sns_plot = sbn.kdeplot(\n",
    "    x=bd[\"longitude\"], \n",
    "    y=bd[\"latitude\"], \n",
    "    fill=True, \n",
    "    cmap=\"viridis_r\", \n",
    "    levels=30, \n",
    "    alpha=0.7, \n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# 4. Dibujar límites de barrios\n",
    "gdf_barrios.boundary.plot(ax=ax, color=\"black\", linewidth=0.3, alpha=0.5)\n",
    "\n",
    "# 5. Añadir nombres de barrios\n",
    "for idx, row in gdf_barrios.iterrows():\n",
    "    centroid = row.geometry.centroid\n",
    "    ax.text(\n",
    "        centroid.x, centroid.y, \n",
    "        str(row[\"NOMBRE\"]), \n",
    "        fontsize=7, color=\"black\", ha=\"center\"\n",
    "    )\n",
    "\n",
    "# 6. Ajustar límites al bounding box de Medellín\n",
    "bounds = gdf_barrios.total_bounds\n",
    "ax.set_xlim(bounds[0], bounds[2])\n",
    "ax.set_ylim(bounds[1], bounds[3])\n",
    "\n",
    "# 7. Crear colorbar manual (gradiente)\n",
    "sm = ScalarMappable(cmap=\"viridis_r\")\n",
    "sm.set_array([])  # necesario para inicializar\n",
    "cbar = f.colorbar(sm, ax=ax, orientation=\"vertical\", fraction=0.03, pad=0.04)\n",
    "cbar.set_label(\"Densidad estimada de eventos\", fontsize=12)\n",
    "\n",
    "# 8. Estilo final\n",
    "ax.set_title(\"Mapa de densidad de eventos de ventas en Medellín\", fontsize=16, pad=20)\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "860d5a93-2d3e-4dd4-b88f-eab495c225df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pointpats import QStatistic\n",
    "\n",
    "coordinates = bd[[\"longitude\", \"latitude\"]].values\n",
    "qstat = QStatistic(coordinates, nx = 2, ny = 2)\n",
    "qstat.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a30c237f-7151-4370-bb87-7fae57ae8473",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Histograma de cantidad de productos vendidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdd3dde8-aa4c-4471-917b-0498aa2b44bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d40438c9-28c7-4672-9e7f-45e484b93a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CLUSTERING CON DBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "# Extraer coordenadas\n",
    "coords = np.array(list(zip(bd.geometry.x, bd.geometry.y)))\n",
    "\n",
    "# DBSCAN con distancia en coordenadas\n",
    "db = DBSCAN(eps=0.01, min_samples=5).fit(coords)  \n",
    "bd[\"cluster\"] = db.labels_\n",
    "\n",
    "# Revisar resultados\n",
    "print(bd[\"cluster\"].value_counts())\n",
    "\n",
    "# Graficar\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "bd.plot(ax=ax, column=\"cluster\", categorical=True, legend=True, markersize=10, cmap=\"tab20\")\n",
    "ax.set_title(\"Clustering de eventos (DBSCAN)\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b8e7c4b-9ad1-4934-8710-88f1d712862c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CLUSTERING CON K-MEANS\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "coords = np.array(list(zip(bd.geometry.x, bd.geometry.y)))\n",
    "kmeans = KMeans(n_clusters=5, random_state=42).fit(coords)\n",
    "bd[\"cluster\"] = kmeans.labels_\n",
    "\n",
    "# Graficar\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "bd.plot(ax=ax, column=\"cluster\", categorical=True, legend=True, markersize=10, cmap=\"tab20\")\n",
    "ax.set_title(\"Clustering de eventos (K-Means)\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c07da9c9-794b-4ecf-bf46-643f178cb342",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(bd[\"quantity_products\"], bins=30, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Histograma de productos vendidos - Poisson No homogenea\", fontsize=16)\n",
    "plt.xlabel(\"Cantidad de productos\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8689e914-6e6e-48f5-a2e1-79eee7511cd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "sbn.boxplot(data=bd, x=\"neighborhood\", y=\"quantity_products\")\n",
    "plt.title(\"Boxplot de productos vendidos por barrio - Uniforme\", fontsize=16)\n",
    "plt.xlabel(\"Barrio\")\n",
    "plt.ylabel(\"Cantidad de productos\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "geopandas",
     "pyarrow",
     "numpy==1.24.4",
     "pandas==2.0.3",
     "scipy==1.11.1",
     "folium",
     "shapely",
     "pointpats",
     "mapclassify"
    ],
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5790031411786163,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02_transform_and_compile",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
